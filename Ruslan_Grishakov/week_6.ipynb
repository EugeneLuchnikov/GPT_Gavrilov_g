{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCUrA9vZVmHG"
      },
      "source": [
        "[Герман Гаврилов](https://drive.google.com/drive/folders/17-r9k1eEGHcVXzGk87dFqfR6FlNfFAYL?usp=sharing) - моя рабочая папка."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVDYF0C9YQcB"
      },
      "source": [
        "# 6 неделя"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9KuUYa49Vo8A"
      },
      "outputs": [],
      "source": [
        "!rm -r sample_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOx_s0fIVwbK",
        "outputId": "ad692f68-b37a-467e-a322-b11ec91a5f69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Подключаем google-диск\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "my_drv_path = '/content/drive/MyDrive/'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Библиотеки"
      ],
      "metadata": {
        "id": "Iki324RBw_iU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install cohere tiktoken==0.5.1 langchain==0.0.339 openai==1.3.4 faiss-cpu==1.7.4 gspread==3.4.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyh3Yc36zjr7",
        "outputId": "6b2e32eb-27af-429a-f5e9-8d44ec0669d2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.9/51.9 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m80.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.5/220.5 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m109.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import timeit\n",
        "import openai\n",
        "import zipfile\n",
        "import getpass\n",
        "import requests\n",
        "import tiktoken\n",
        "\n",
        "from   openai  import OpenAI\n",
        "from   IPython import display\n",
        "\n",
        "from   langchain.vectorstores      import FAISS\n",
        "from   langchain.docstore.document import Document\n",
        "from   langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from   langchain.text_splitter     import MarkdownHeaderTextSplitter, RecursiveCharacterTextSplitter\n",
        "\n",
        "import gspread                     # API для работы с Google таблицами\n",
        "from   google.colab import auth    # модуль для аутентификации\n",
        "from   google.auth  import default # модуль для работы с учётными данными"
      ],
      "metadata": {
        "id": "krMfszKi1NA6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Функции"
      ],
      "metadata": {
        "id": "C-vZQuEF4R93"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция для ввода OpenAI API-ключа\n",
        "def get_key_ОpenAI():\n",
        "  openai.api_key = getpass.getpass('OpenAI API Key:')\n",
        "  os.environ['OPENAI_API_KEY'] = openai.api_key"
      ],
      "metadata": {
        "id": "75LhQ0Vr4v2t"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `chat_functions.py`"
      ],
      "metadata": {
        "id": "qnemPNyQZhfE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def num_tokens_from_string(string: str) -> int:\n",
        "  \"\"\"Возвращает количество токенов в строке.\"\"\"\n",
        "\n",
        "  # Выбор кодировщика (`cl100k_base` используется для `gpt-4`, `gpt-3.5-turbo`, `text-embedding-ada-002`)\n",
        "  encoding = tiktoken.get_encoding('cl100k_base')\n",
        "\n",
        "  # Разбивка строки на токены и подсчёт из количества\n",
        "  num_tokens = len(encoding.encode(string))\n",
        "\n",
        "  return num_tokens\n",
        "#\n",
        "#\n",
        "def split_text(text, verbose=0):\n",
        "  \"\"\"Функция разбивает текст на чанки.\"\"\"\n",
        "\n",
        "  # Шаблон MarkdownHeaderTextSplitter, по которому будет делиться переданный текст в формате Markdown\n",
        "  headers_to_split_on = [('#',    'Header 1'),\n",
        "                         ('##',   'Header 2'),\n",
        "                         ('###',  'Header 3'),\n",
        "                         ('####', 'Header 4')]\n",
        "\n",
        "  # Создаём экземпляр сплиттера\n",
        "  text_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
        "  #text_splitter = RecursiveCharacterTextSplitter(separators=[\"##_\", \"\\n\\n\", \"\\n\", \" \", \"\"],\n",
        "  #                                               chunk_size=1024,\n",
        "  #                                               length_function=lambda x: num_tokens_from_string(x))\n",
        "\n",
        "  # Получаем список чанков\n",
        "  source_chunks = text_splitter.split_text(text)\n",
        "\n",
        "  # Обработка чанков\n",
        "  chank_count = len(source_chunks)\n",
        "  for number, chank in enumerate(source_chunks):\n",
        "\n",
        "    # Добавление информации в метаданные чанка о его номере в базе\n",
        "    chank.metadata['chank'] = f'{number+1}/{chank_count}'\n",
        "\n",
        "    # Вывод количества слов/токенов во фрагменте, если включен режим verbose\n",
        "    if verbose:\n",
        "      count = num_tokens_from_string(chank.page_content)\n",
        "      print(f\"\\n Chank#{number+1}/{chank_count}. Tokens in text = {count}\\n {'-' * 20}\\n{insert_newlines(str(chank))}\\n{'=' * 20}\")\n",
        "\n",
        "  # Возвращение списка фрагментов текста\n",
        "  return source_chunks\n",
        "#\n",
        "#\n",
        "def create_embedding(data, verbose=0):\n",
        "  \"\"\"Функция преобразует текстовую Базу знаний в векторную.\"\"\"\n",
        "\n",
        "  # Разбивка текста на чанки\n",
        "  source_chunks = []\n",
        "  source_chunks = split_text(text=data, verbose=verbose)\n",
        "\n",
        "  # Создание векторной Базы знаний на основе чанков\n",
        "  search_index = FAISS.from_documents(source_chunks, OpenAIEmbeddings(), )\n",
        "\n",
        "  # Подсчёт общего количества токенов во всех чанках\n",
        "  count_token = num_tokens_from_string(' '.join([x.page_content for x in source_chunks]))\n",
        "\n",
        "  # Печать сводной информации по созданию векторной Базы знаний\n",
        "  print('\\n==================== ')\n",
        "  print('Количество токенов в документе :', count_token)\n",
        "\n",
        "  # Стоимость эмбеддинга согласно прайса на 22.11.2023 - 0,0001/1К токенов (https://openai.com/pricing#language-models)\n",
        "  print('ЦЕНА запроса:', 0.0001*(count_token/1000), ' $')\n",
        "  print('==================== ')\n",
        "\n",
        "  return search_index\n",
        "#\n",
        "#\n",
        "def load_file(url: str):\n",
        "  \"\"\"Функция загрузки документа по url как текст.\"\"\"\n",
        "\n",
        "  try:\n",
        "    response = requests.get(url) # получение документа по url\n",
        "    response.raise_for_status()  # проверка ответа и если была ошибка - формирование исключения\n",
        "    return response.text\n",
        "\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "#\n",
        "#\n",
        "def load_search_indexes(url: str, verbose=0):\n",
        "  \"\"\"Функция загружает текстовую Базу знаний и преобразует её в векторную.\"\"\"\n",
        "\n",
        "  try:\n",
        "    return create_embedding(load_file(url), verbose=verbose)\n",
        "\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "#\n",
        "#\n",
        "def insert_newlines(text: str, max_len: int = 120) -> str:\n",
        "  \"\"\"Функция форматирует переданный текст по длине для лучшего восприятия на экране.\"\"\"\n",
        "\n",
        "  words = text.split()\n",
        "  lines = []\n",
        "  current_line = ''\n",
        "\n",
        "  for word in words:\n",
        "    if len(current_line + ' ' + word) > max_len:\n",
        "      lines.append(current_line)\n",
        "      current_line = ''\n",
        "    current_line += ' ' + word\n",
        "\n",
        "  lines.append(current_line)\n",
        "\n",
        "  return '\\n'.join(lines)\n",
        "#\n",
        "#\n",
        "def filtred_docs (docs, limit_score):\n",
        "  \"\"\"Функция удаляет из отобранных чанков чанки, у которых score выше значения limit_score.\n",
        "     При этом limit_score определяет гарантированно ошибочные чанки.\n",
        "     Далее отбор чанков идёт в зависимости от значения score первого не нулевого score.\n",
        "     Если есть чанк с score=0, он оставляется единственным.\n",
        "     Если limit_score = 0, то чанки не фильтруются.\"\"\"\n",
        "\n",
        "  if bool(limit_score):\n",
        "    r = []\n",
        "    score = 0\n",
        "\n",
        "    def set_score(d, sc):\n",
        "      d[0].metadata['score'] = sc\n",
        "      return d\n",
        "\n",
        "    for doc in docs:\n",
        "\n",
        "      s = doc[1]\n",
        "      if s==0:\n",
        "        r.append(set_score(doc[0],s))\n",
        "        break\n",
        "      if score==0:\n",
        "        if s<.2: score = s*1.7\n",
        "        elif s<.3: score = s+.05\n",
        "        else: score = s+.01\n",
        "        if score>limit_score: score = limit_score\n",
        "      if s<score: r.append(set_score(doc,s))\n",
        "\n",
        "    print(f'Фильр пропустил чанк(ов): {len(r)} из {len(docs)}')\n",
        "\n",
        "  else:\n",
        "    r = docs\n",
        "\n",
        "  return r\n",
        "#\n",
        "#\n",
        "def answer_index(model,\n",
        "                 system,\n",
        "                 topic: str,\n",
        "                 query,\n",
        "                 search_index,\n",
        "                 temp=0,\n",
        "                 verbose_documents=0,\n",
        "                 verbose_price=0,\n",
        "                 top_documents=8,\n",
        "                 limit_score=0.0):\n",
        "  \"\"\"Основная функция, которая формирует запрос и получает ответ от OpenAI по заданному вопросу на основе векторной Базы знаний.\"\"\"\n",
        "\n",
        "  # Выбор варианта вопроса: если есть query, то вопрос задан из группового запроса, и он имеет приоритет\n",
        "  question = query['question'] if bool(query) else topic\n",
        "\n",
        "  # Выборка релевантных чанков\n",
        "  docs = filtred_docs(search_index.similarity_search_with_score(question, k=top_documents), limit_score)\n",
        "\n",
        "  \"\"\"Этот блок закоментирован.\n",
        "     Рассматривается возможность даполнительного запроса с фильтрацией чанков по метаданным.\n",
        "     Пока нереализовано.\"\"\"\n",
        "  #for i, doc in enumerate(docs):\n",
        "  #  header1 = doc[0].metadata.get('Header 1')\n",
        "  #  print(f'{i}. {header1}. Score: {doc[1]}')\n",
        "  #  if header1=='Оценка' or header1=='Экспертиза':\n",
        "  #    #docs = search_index.similarity_search_with_score(question, k=top_documents,)\n",
        "  #    #print(f'{i}. {header1}. Score: {doc[1]}')\n",
        "  #    pass\n",
        "\n",
        "  message_content = ''            # контекст для GPT\n",
        "  message_content_display = ''    # контекст для вывода на экран\n",
        "\n",
        "  for i, doc in enumerate(docs):\n",
        "\n",
        "    # Формирование контекста для запроса GPT и показа на экран отобранных чанков\n",
        "    message_content = message_content + f'Отрывок документа №{i+1}:{doc[0].page_content}'\n",
        "    message_content_display = message_content_display + f\"\\n Отрывок документа №{i+1}. Chank № {doc[0].metadata.get('chank')}. Score({str(round(doc[1], 3))})\\n -----------------------\\n{insert_newlines(doc[0].page_content)}\\n\"\n",
        "\n",
        "    # Сбор информации для группого запроса\n",
        "    if bool(query):\n",
        "\n",
        "      # Выделение из строки метаданных ссылки: если нет - присваиваем пустую строку\n",
        "      search_link_h1 = re.search(r'\\[(.*?)\\]', doc[0].metadata.get('Header 1')) if bool(doc[0].metadata.get('Header 1')) else ''\n",
        "      search_link_h2 = re.search(r'\\[(.*?)\\]', doc[0].metadata.get('Header 2')) if bool(doc[0].metadata.get('Header 2')) else ''\n",
        "      search_link_h3 = re.search(r'\\[(.*?)\\]', doc[0].metadata.get('Header 3')) if bool(doc[0].metadata.get('Header 3')) else ''\n",
        "      search_link_h4 = re.search(r'\\[(.*?)\\]', doc[0].metadata.get('Header 4')) if bool(doc[0].metadata.get('Header 4')) else ''\n",
        "\n",
        "      # Выбор самой внутренней ссылки: если несколько ссылок, то самая внутренняя ссылается на расположение чанка на сайте\n",
        "      link = ''\n",
        "      if bool(search_link_h4): link = search_link_h4.group(1)\n",
        "      elif bool(search_link_h3): link = search_link_h3.group(1)\n",
        "      elif bool(search_link_h2): link = search_link_h2.group(1)\n",
        "      elif bool(search_link_h1): link = search_link_h1.group(1)\n",
        "\n",
        "      # Заполнение запроса выбранными чанками\n",
        "      query[f'chank_{i+1}'] = f\"Chank № {doc[0].metadata.get('chank')}. Score({str(round(doc[1], 3))}).\\n{doc[0].page_content}.\\n--------\\n{link}\"\n",
        "\n",
        "  # Вывод на экран отобранных чанков\n",
        "  if (verbose_documents): print(message_content_display)\n",
        "\n",
        "  # Отправка запроса к Open AI\n",
        "  completion = OpenAI().chat.completions.create(model = model[0],\n",
        "                                                messages = [{'role': 'system', 'content': system},\n",
        "                                                            {'role': 'user',   'content': f'Документ с информацией для ответа пользователю: {message_content}.\\n\\nВопрос клиента: {question}'}],\n",
        "                                                temperature=temp)\n",
        "\n",
        "  # Подсчёт токенов и стоимости\n",
        "  prompt_tokens = completion.usage.prompt_tokens\n",
        "  total_tokens = completion.usage.total_tokens\n",
        "  price_prompt_tokens = prompt_tokens * model[1]/1000\n",
        "  price_answer_tokens = (total_tokens - prompt_tokens) * model[2]/1000\n",
        "  price_total_token = price_prompt_tokens + price_answer_tokens\n",
        "\n",
        "  # Сбор информации для группого запроса\n",
        "  if bool(query):\n",
        "    query['price_query'] = price_total_token\n",
        "    query['price_question'] = price_prompt_tokens\n",
        "    query['price_answer'] = price_answer_tokens\n",
        "    query['token_query'] = total_tokens\n",
        "    query['token_question'] = prompt_tokens\n",
        "    query['token_answer'] = total_tokens - prompt_tokens\n",
        "\n",
        "  # Вывод на экран стоимости запроса\n",
        "  if (verbose_price):\n",
        "    print('\\n======================================================= ')\n",
        "    print(f'{prompt_tokens} токенов использовано на вопрос. Цена: {round(price_prompt_tokens, 6)} $.')\n",
        "    print(f'{total_tokens - prompt_tokens} токенов использовано на ответ.  Цена: {round(price_answer_tokens, 6)} $.')\n",
        "    print(f'{total_tokens} токенов использовано всего.     Цена: {round(price_total_token, 6)} $')\n",
        "    print('======================================================= ')\n",
        "\n",
        "  # Ответ OpenAI\n",
        "  return completion.choices[0].message.content\n",
        "#\n",
        "#\n",
        "def question_normalization(text):\n",
        "  \"\"\"Функция нормализует текст вопроса.\n",
        "     Удаляет лишние пробелы, символы, знаки. Делает первое слово с заглавной буквы.\"\"\"\n",
        "\n",
        "  ## Удаление символов \"!?.,-\" из текста\n",
        "  #text = re.sub(r'[-!?_]', '', text) # '[-!?.,_]'\n",
        "\n",
        "  # Разделение текста на слова\n",
        "  words = text.split()\n",
        "\n",
        "  ## Проход по каждому слову\n",
        "  #for i in range(len(words)):\n",
        "  #\n",
        "  #  # Если слово состоит из заглавных букв и длина больше 1 символа, считаем это аббревиатурой\n",
        "  #  if words[i].isupper() and len(words[i]) > 1: continue # пропускаем аббревиатуры\n",
        "  #  else: words[i] = words[i].lower() # преобразуем в нижний регистр\n",
        "\n",
        "  ## Преобразуем первое слово в строке к верхнему регистру\n",
        "  #words[0] = words[0].capitalize()\n",
        "\n",
        "  # Объединяем слова обратно в строку\n",
        "  return ' '.join(words)\n",
        "#\n",
        "#\n",
        "def load_bd_text(url: str, verbose=0):\n",
        "  \"\"\"Функция загружает текстовую Базу знаний и преобразует её в векторную.\"\"\"\n",
        "\n",
        "  response = requests.get(url) # получение документа по url\n",
        "  response.raise_for_status()  # проверка ответа, и если была ошибка - формирование исключения\n",
        "\n",
        "  return create_embedding(response.text, verbose=verbose)\n",
        "#\n",
        "#\n",
        "def load_bd_vect(name, url: str, verbose=0):\n",
        "  \"\"\"Функция загружает векторную Базу знаний.\"\"\"\n",
        "\n",
        "  # bd_index\n",
        "  name_bd = name + '.zip'\n",
        "\n",
        "  # Скачивание архива Базы знаний\n",
        "  response = requests.get(url) # получение документа по url\n",
        "  response.raise_for_status()  # проверка ответа, и если была ошибка - формирование исключения\n",
        "\n",
        "  # Сохранение архива\n",
        "  with open(name_bd, 'wb') as file:\n",
        "    file.write(response.content)\n",
        "\n",
        "  # Разархивирование Базы знаний\n",
        "  with zipfile.ZipFile(name_bd, 'r') as zip:\n",
        "    zip.extractall()\n",
        "\n",
        "  # Загрузка векторной Базы знаний\n",
        "  bd = FAISS.load_local(name, OpenAIEmbeddings())\n",
        "\n",
        "  if verbose:\n",
        "\n",
        "    docs = bd.similarity_search_with_score('', k=10000)\n",
        "    docs_sorted = sorted(docs, key=lambda x: int(x[0].metadata.get('chank').split('/')[0]))\n",
        "\n",
        "    for doc in docs_sorted:\n",
        "      count = num_tokens_from_string(doc[0].page_content)\n",
        "      print(f\"\\n Chank#{doc[0].metadata.get('chank')}. Tokens in text = {count}\\n {'-' * 20} \\n{insert_newlines(str(doc))}\\n{'=' * 20}\")\n",
        "    print()\n",
        "\n",
        "  return bd\n",
        "#\n",
        "#\n",
        "def load_bd(name, url_vect: str, url_text: str, verbose=0):\n",
        "  \"\"\"Функция организует очерёдность загрузки Базы знаний.\n",
        "     Сначала идёт загрузка векторной базы, если она не загружается,\n",
        "     то загружается база в текстовом формате и потом преобразуется в векторную.\"\"\"\n",
        "\n",
        "  try:\n",
        "    bd = load_bd_vect(name, url_vect, verbose)\n",
        "    print('Загрузка векторной Базы знаний выполнена успешно.')\n",
        "    return bd\n",
        "\n",
        "  except Exception as e:\n",
        "    print('По указанной ссылке векторной Базы знаний нет.')\n",
        "    print(e)\n",
        "    print('\\nИдёт загрузка текстовой Базы знаний...')\n",
        "\n",
        "    try:\n",
        "      bd = load_bd_text(url_text, verbose)\n",
        "      print('\\nЗагрузка текстовой Базы знаний выполнена успешно.')\n",
        "      return bd\n",
        "\n",
        "    except Exception as e:\n",
        "      print('\\nПо указанной ссылке текстовой Базы знаний нет.')\n",
        "      print(e)\n",
        "      print('\\nОшибка загрузки!')\n",
        "#\n",
        "#\n",
        "def archive_bd(folder_to_zip, output_filename, index_db):\n",
        "  \"\"\"Архивирование Базы знаний (при необходимости).\n",
        "     В дальнейшем архив нужно поместить на GitHub.\"\"\"\n",
        "\n",
        "  # Сохранение папки с векторной Базой знаний\n",
        "  index_db.save_local(folder_to_zip)\n",
        "\n",
        "  # Архивирование папки с векторной Базой знаний\n",
        "  with zipfile.ZipFile(output_filename, 'w') as zip:\n",
        "    for root, dirs, files in os.walk(folder_to_zip):\n",
        "      for file in files:\n",
        "        zip.write(os.path.join(root, file))\n",
        "  print(f'База знаний - заархивирована. Имя файла - {output_filename}.')\n",
        "\n",
        "\n",
        "# Данные по названиям модели и стоимости токена на 22.11.2023 (https://openai.com/pricing#language-models)\n",
        "# Псевдоним = ['Имя модели', 'Цена токена - вопроса', 'Цена токена - ответа']\n",
        "MODEL_GPT_4_1106_PREVIEW = ['gpt-4-1106-preview', 0.01,  0.03 ] # 128K tokens\n",
        "MODEL_GPT_3_5_TURBO_1106 = ['gpt-3.5-turbo-1106', 0.001, 0.002] #  16K tokens\n",
        "\n",
        "MODEL_COST = {x[0]:x for x in [MODEL_GPT_4_1106_PREVIEW, MODEL_GPT_3_5_TURBO_1106]}"
      ],
      "metadata": {
        "id": "-c7DQFPA6L_d"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `chat_gspread.py`"
      ],
      "metadata": {
        "id": "12NdiiqSZxkL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ChatSheetQuestions:\n",
        "\n",
        "  # Введём словарь, чтобы можно было обращаться по имени к столбцу\n",
        "  column_name = {'Вопрос':      0,\n",
        "                 'Ответ':       1,\n",
        "                 'Оценка':      2,\n",
        "                 'Комментарий': 3,\n",
        "                 'Ошибка':      4,\n",
        "                 'Модель':      5,\n",
        "                 'Промпт':      6,\n",
        "                 'Чанк №1':     7,\n",
        "                 'Чанк №2':     8,\n",
        "                 'Чанк №3':     9,\n",
        "                 'Чанк №4':    10,\n",
        "                 'Чанк №5':    11,\n",
        "                 'Чанк №6':    12,\n",
        "                 'Чанк №7':    13,\n",
        "                 'Чанк №8':    14}\n",
        "\n",
        "  top_documents = 3\n",
        "  temperature = 0\n",
        "  limit_score = 0\n",
        "  question_norma = False\n",
        "  chat_prompt = ''\n",
        "  bd_index = None\n",
        "  gpt_model = 'gpt-3.5-turbo-1106'\n",
        "\n",
        "  SELECT_MODEL_GPT = MODEL_COST[gpt_model]\n",
        "\n",
        "\n",
        "  def __init__(self, url_table, gc_auth) -> None:\n",
        "    # Название файла с вопросами.\n",
        "    # Ссылка на общий файл.\n",
        "    try:\n",
        "\n",
        "      self.spreadsheet = gc_auth.open_by_url(url_table)\n",
        "      print(f'Подключились к документу - {self.spreadsheet.title}')\n",
        "\n",
        "      # Получаем список всех страниц файла\n",
        "      self.worksheet_list = self.spreadsheet.worksheets()\n",
        "      print('\\nСтраницы документа:')\n",
        "      print('-------------------')\n",
        "      for i, worksheet in enumerate(self.worksheet_list):\n",
        "        print(f'{i}. {worksheet.title}')\n",
        "\n",
        "    except Exception as e:\n",
        "\n",
        "      print(e)\n",
        "      print(f'Ошибка подключения к документу. Проверьте ссылку.')\n",
        "\n",
        "\n",
        "  def select_sheet(self, number_sheet=1):\n",
        "    # Выбор страницы в таблице.\n",
        "    # Устанавливаем номер рабочего листа по списку выше.\n",
        "    self.number_sheet = number_sheet\n",
        "    for c in self.column_name: self.column_name[c] = -1\n",
        "\n",
        "    if not number_sheet==None:\n",
        "\n",
        "      # Выбор нужного листа из списка\n",
        "      self.worksheet = self.worksheet_list[number_sheet]\n",
        "      worksheet = self.worksheet\n",
        "\n",
        "      # Проверка текущей страницы\n",
        "      print(f'Текущая страница - \"{worksheet.title}\"\\n')\n",
        "\n",
        "      # Список всех столбцов на странице\n",
        "      print('-----№---------Название---')\n",
        "      for i, col in enumerate(worksheet.row_values(1)):\n",
        "        print(f'Колонка №{i+1:<2} {col}')\n",
        "        self.column_name[col] = i\n",
        "\n",
        "    else: print('Введите номер страницы.')\n",
        "\n",
        "\n",
        "  def load_sheet(self):\n",
        "    # Загрузка вопросов.\n",
        "\n",
        "    column_question = self.column_name['Вопрос']\n",
        "    #print(f'column_question = {column_question}')\n",
        "    verbose_question = 0 # @param {type:\"integer\"} #\n",
        "\n",
        "    worksheet = self.worksheet\n",
        "    # В данном блоке происходит заполнение списка запросов вопросами и дополнительной\n",
        "    # информацией с выбранного листа. Загрузка выполняется ВСЕХ строк с вопросами для\n",
        "    # последующей корректной работы. Далее из этого списка выбирается нужный диапазон\n",
        "    # вопросов для группового запроса к GPT.\n",
        "\n",
        "    # Выбор всех вопросов\n",
        "    column = worksheet.col_values(column_question+1)\n",
        "    #print(f'column = {column}')\n",
        "\n",
        "    if self.question_norma: print('Вопросы будут нормализованы.')\n",
        "\n",
        "    # Создаём пустой список запросов\n",
        "    list_query = []\n",
        "    column_name = self.column_name\n",
        "    r_question  = column_name['Вопрос']\n",
        "    r_appraisal = column_name['Оценка']\n",
        "\n",
        "    # Заполнение списка запросов информацией с выбранного листа\n",
        "    for i in range(len(column)-1):\n",
        "\n",
        "      row = worksheet.row_values(i+2)\n",
        "\n",
        "      # Считывание ячеек с контролем их наличия для избежании ошибки чтения\n",
        "      # Проверить индексы row со списком в ячейке выше\n",
        "      question = row[r_question] if len(row)>r_question else ''    # вопрос\n",
        "      appraisal = row[r_appraisal] if len(row)>r_appraisal else '' # оценка\n",
        "\n",
        "      # Нормализация вопроса\n",
        "      question = question_normalization(question) if self.question_norma else question\n",
        "\n",
        "\n",
        "      # Словарь запроса\n",
        "      query = {\n",
        "                'line':           i+2,              # номер строки в документе: берём строки с вопросами\n",
        "                'question':       question,         # вопрос\n",
        "                'answer_gpt':     '',               # ответ GPT\n",
        "                'appraisal':      appraisal,        # оценка ответа\n",
        "                'bug':            '',               # ошибка\n",
        "                'comments':       '',               # комментарии\n",
        "                'chank_1':        '',               # чанк №1\n",
        "                'chank_2':        '',               # чанк №2\n",
        "                'chank_3':        '',               # чанк №3\n",
        "                'chank_4':        '',               # чанк №4\n",
        "                'chank_5':        '',               # чанк №5\n",
        "                'chank_6':        '',               # чанк №6\n",
        "                'chank_7':        '',               # чанк №7\n",
        "                'chank_8':        '',               # чанк №8\n",
        "                'gpt_model':      self.gpt_model,   # модель GPT\n",
        "                'chat_prompt':    self.chat_prompt, # промпт\n",
        "                'price_query':    0,                # стоимость запроса общая\n",
        "                'price_question': 0,                # стоимость вопроса с контекстом\n",
        "                'price_answer':   0,                # стоимость ответа\n",
        "                'token_query':    0,                # количество токенов всего: вопрос-ответ\n",
        "                'token_question': 0,                # количество токенов в вопросе с контекстом\n",
        "                'token_answer':   0,                # количество токенов в ответе\n",
        "      }\n",
        "      list_query.append(query)\n",
        "\n",
        "    # Вывод вопросов\n",
        "    if verbose_question:\n",
        "      for query in list_query:\n",
        "        print(f'Строка №{query[\"line\"]}. Вопрос: {query[\"question\"]}')\n",
        "\n",
        "    # Диапазон строк с вопросами на выбранной странице\n",
        "    print(f'\\n\\nЗагрузка списка вопросов завершена. Количество вопросов: {len(column)-1}.')\n",
        "    print(f\"Диапазон номеров строк с вопросами (включительно): [{list_query[0]['line']}:{list_query[-1]['line']}].\")\n",
        "    self.list_query = list_query\n",
        "    #print(list_query)\n",
        "\n",
        "\n",
        "  def execute(self,  row_first = 2, row_end = 2, verbose_answer = 0, verbose_chank = 0):\n",
        "\n",
        "    # @title Выбор диапазона вопросов группого запроса. Отправка запроса. { vertical-output: true }\n",
        "\n",
        "    # Определение диапазона строк с вопросами. Начало диапазона, конец диапазона (включительно).\n",
        "\n",
        "    # Если подвис ответ от GPT можно прервать обработку, установить row_first\n",
        "    # в значение на которой была прервана обработка и запустить обработку заново.\n",
        "    # Ранее обработанные вопросы будут сохранены в файле.\n",
        "\n",
        "    # Обнуление общих затрат на групповой запрос\n",
        "    total_price_query, total_token_query, total_query = 0, 0, 0\n",
        "\n",
        "    # Фиксация времени\n",
        "    start_group = timeit.default_timer()\n",
        "\n",
        "    list_query = self.list_query\n",
        "    for query in list_query[row_first-2:row_end-1]:\n",
        "\n",
        "      # Проверка на пустой вопрос: если пустой - пропуск цикла\n",
        "      if not bool(query['question'].strip()):\n",
        "        print(f'На строке № {query[\"line\"]} - вопроса нет.')\n",
        "        continue\n",
        "\n",
        "      # Отправка запроса, фиксация времени\n",
        "      start = timeit.default_timer()\n",
        "      try:\n",
        "        query['answer_gpt'] = answer_index(model = self.SELECT_MODEL_GPT,\n",
        "                                           system = self.chat_prompt,\n",
        "                                           topic = '',\n",
        "                                           query = query,\n",
        "                                           search_index = self.bd_index,\n",
        "                                           temp = self.temperature,\n",
        "                                           verbose_documents = 0,\n",
        "                                           verbose_price = 0,\n",
        "                                           top_documents = self.top_documents,\n",
        "                                           limit_score = self.limit_score)\n",
        "        total_price_query += query['price_query']\n",
        "        total_token_query += query['token_query']\n",
        "        total_query +=1\n",
        "      except Exception as e:\n",
        "        print(f'Ошибка ответа GPT на строке №{query[\"line\"]}. - {e}')\n",
        "      end = timeit.default_timer()\n",
        "\n",
        "      # Сообщение об успешности ответа от GPT\n",
        "      print(f'Строка №{query[\"line\"]}. Ответ на вопрос получен за - {round(end-start, 3)} сек.')\n",
        "\n",
        "      # Запись ответа в файл\n",
        "      worksheet = self.worksheet\n",
        "      r_answer_gpt = self.column_name['Ответ GPT']\n",
        "      r_gpt_model = self.column_name['Модель GPT']\n",
        "      r_prompt = self.column_name['Промпт']\n",
        "      r_chank_1 = self.column_name['Чанк №1']\n",
        "      r_chank_2 = self.column_name['Чанк №2']\n",
        "      r_chank_3 = self.column_name['Чанк №3']\n",
        "      r_chank_4 = self.column_name['Чанк №4']\n",
        "      r_chank_5 = self.column_name['Чанк №5']\n",
        "      r_chank_6 = self.column_name['Чанк №6']\n",
        "      r_chank_7 = self.column_name['Чанк №7']\n",
        "      r_chank_8 = self.column_name['Чанк №8']\n",
        "\n",
        "      def update_cell(row, name):\n",
        "        worksheet.update_cell(query['line'], row+1, query[name]) # ответ GPT\n",
        "\n",
        "      try:\n",
        "        if bool(query['answer_gpt']):\n",
        "          update_cell(r_answer_gpt, 'answer_gpt') # ответ GPT\n",
        "          update_cell(r_gpt_model, 'gpt_model')   # модель GPT\n",
        "          update_cell(r_prompt, 'chat_prompt')    # промпт\n",
        "          update_cell(r_chank_1, 'chank_1')       # чанк №1\n",
        "          update_cell(r_chank_2, 'chank_2')       # чанк №2\n",
        "          update_cell(r_chank_3, 'chank_3')       # чанк №3\n",
        "          update_cell(r_chank_4, 'chank_4')       # чанк №4\n",
        "          update_cell(r_chank_5, 'chank_5')       # чанк №5\n",
        "          update_cell(r_chank_6, 'chank_6')       # чанк №6\n",
        "          update_cell(r_chank_7, 'chank_7')       # чанк №7\n",
        "          update_cell(r_chank_8, 'chank_8')       # чанк №8\n",
        "\n",
        "          print(f'Строка №{query[\"line\"]}. Ответ записан в файл.')\n",
        "\n",
        "          # Контроль номализации вопроса и перезапись его в таблице\n",
        "          if self.question_norma:\n",
        "            question_old = worksheet.row_values(query['line'])[self.column_question]\n",
        "            if not (question_old == query['question']):\n",
        "              print(\"    Вопрос нормализован и перезаписан в таблице.\")\n",
        "              print(f\"    Старый вариант: {question_old}\")\n",
        "              print(f\"    Новый вариант : {query['question']}\")\n",
        "              worksheet.update_cell(query['line'], self.column_question+1, query['question'])\n",
        "      except Exception as e:\n",
        "        print('\\n========================================================')\n",
        "        print(f'!!!Ошибка записи строки №{query[\"line\"]} в файл. - {e}')\n",
        "        print('========================================================')\n",
        "\n",
        "    end_group = timeit.default_timer()\n",
        "\n",
        "    # Вывод вопросов и ответов\n",
        "    if verbose_answer:\n",
        "      for i, query in enumerate(list_query):\n",
        "        if query['answer_gpt']:\n",
        "          print()\n",
        "          print(insert_newlines(f\"ВОПРОС №{i+2}: {query['question']}\"))\n",
        "          print('---------------------------')\n",
        "          print(insert_newlines(f\"\\nОТВЕТ: {query['answer_gpt']}\"))\n",
        "          print('===========================\\n')\n",
        "          if verbose_chank:\n",
        "            print(query['chank_1'])\n",
        "            print()\n",
        "            print(query['chank_2'])\n",
        "            print()\n",
        "            print(query['chank_3'])\n",
        "            print()\n",
        "            print(query['chank_4'])\n",
        "            print()\n",
        "            print(query['chank_5'])\n",
        "            print()\n",
        "            print(query['chank_6'])\n",
        "            print()\n",
        "            print(query['chank_7'])\n",
        "            print()\n",
        "            print(query['chank_8'])\n",
        "\n",
        "    print()\n",
        "    print('-------------------------------------------')\n",
        "    print(f'Вопросов в пакетной обработке - {total_query} шт.')\n",
        "    print(f'Время пакетной обработки      - {round(end_group-start_group, 1)} сек.')\n",
        "    print(f'Стоимость пакетной обработки  - {round(total_price_query, 4)} $.')\n",
        "    print(f'Токенов в пакетной обработке  - {total_token_query} шт.')"
      ],
      "metadata": {
        "id": "q0SylHrbafds"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ввод API ключа"
      ],
      "metadata": {
        "id": "6hJrrs6v6De2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_key_ОpenAI()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoV9tGwXGTGS",
        "outputId": "e67062a2-6222-40db-f593-38bdc0de7468"
      },
      "execution_count": 6,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI API Key:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Таблица с результатами тестирования"
      ],
      "metadata": {
        "id": "Sn5N4dk08DU4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Выбор источника `Базы знаний`\n",
        "\"\"\" !!! ПАРАМЕТРЫ БАЗЫ ЗНАНИЙ !!! \"\"\"\n",
        "\n",
        "\"\"\"\n",
        "Сначала идёт попытка загрузки векторной БЗ. Если она неудачна, то идёт загрузка текстовой БЗ.\n",
        "\n",
        "============================ ЧИТАЙТЕ СООБЩЕНИЯ: ЧТО ЗАГРУЗИЛОСЬ! ============================\n",
        "\"\"\"\n",
        "\n",
        "# Ссылка на Базу знаний на Github в текстовом формате\n",
        "link_bd_text = 'https://raw.githubusercontent.com/terrainternship/GPT_Gavrilov_g/main/knowledge_base/TelegramPosts.md' #@param string\n",
        "\n",
        "# Сылка на Базу знаний на Github в векторном формате\n",
        "link_bd_vect = '' #@param string\n",
        "\n",
        "# Показывать полученные чанки\n",
        "verbose_bd = 0 #@param Показывать полученные чанки string\n",
        "\n",
        "# Загрузка Базы знаний\n",
        "TelegramPosts_bd_index = load_bd('TelegramPosts_bd_index', link_bd_vect, link_bd_text, verbose=verbose_bd)"
      ],
      "metadata": {
        "id": "N6EfzRZy58dT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "af6c33f5-d2a4-4af5-8330-c34c2e5ad0cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "По указанной ссылке векторной Базы знаний нет.\n",
            "Invalid URL '': No scheme supplied. Perhaps you meant https://?\n",
            "\n",
            "Идёт загрузка текстовой Базы знаний...\n",
            "\n",
            "==================== \n",
            "Количество токенов в документе : 88943\n",
            "ЦЕНА запроса: 0.0088943  $\n",
            "==================== \n",
            "\n",
            "Загрузка текстовой Базы знаний выполнена успешно.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Архивируем Базу знаний в векторном формате\n",
        "archive_bd('TelegramPosts_bd_index', 'TelegramPosts_bd_index.zip', TelegramPosts_bd_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLcSVlijv2A2",
        "outputId": "0289537e-ff9b-40dd-e2a3-c16e0e701be4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "База знаний - заархивирована. Имя файла - TelegramPosts_bd_index.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Выбор источника `Базы знаний`\n",
        "\"\"\" !!! ПАРАМЕТРЫ БАЗЫ ЗНАНИЙ !!! \"\"\"\n",
        "\n",
        "\"\"\"\n",
        "Сначала идёт попытка загрузки векторной БЗ. Если она неудачна, то идёт загрузка текстовой БЗ.\n",
        "\n",
        "============================ ЧИТАЙТЕ СООБЩЕНИЯ: ЧТО ЗАГРУЗИЛОСЬ! ============================\n",
        "\"\"\"\n",
        "\n",
        "# Ссылка на Базу знаний на Github в текстовом формате\n",
        "link_bd_text = 'https://raw.githubusercontent.com/terrainternship/GPT_Gavrilov_g/main/knowledge_base/TelegramPosts.md' #@param string\n",
        "\n",
        "# Сылка на Базу знаний на Github в векторном формате\n",
        "link_bd_vect = 'https://github.com/terrainternship/GPT_Gavrilov_g/raw/main/knowledge_base/TelegramPosts_bd_index.zip' #@param string\n",
        "\n",
        "# Показывать полученные чанки\n",
        "verbose_bd = 0 #@param Показывать полученные чанки string\n",
        "\n",
        "# Загрузка Базы знаний\n",
        "TelegramPosts_bd_index = load_bd('TelegramPosts_bd_index', link_bd_vect, link_bd_text, verbose=verbose_bd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "b0a9c08c-6cf7-40af-e6bb-43140538f391",
        "id": "qgsfabkUzUKX"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Загрузка векторной Базы знаний выполнена успешно.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url_table = 'https://docs.google.com/spreadsheets/d/13Z73lWK8bnOHtHnY9ChaUeou-b9unryV4JP87cKJuS4/edit?usp=sharing' #@param string"
      ],
      "metadata": {
        "id": "iIMzsP_R8L-g"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "auth.authenticate_user()      # аутентифицируем текущего пользователя Colab\n",
        "creds, _ = default()          # создаём объект учётных данных на основе аутентификации\n",
        "gc = gspread.authorize(creds) # создаём клиента для таблиц на основе учётных данных\n",
        "\n",
        "g = ChatSheetQuestions(url_table, gc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GvJpILS9E06",
        "outputId": "47d9bbbc-fab3-46ae-fa35-5e5c289b27ea"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Подключились к документу - Тестирование БЗ German Gavrilov\n",
            "\n",
            "Страницы документа:\n",
            "-------------------\n",
            "0. Стажёры\n",
            "1. Аникеев\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_COST"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ckrr-CaXwTeb",
        "outputId": "6858d003-9872-49ea-d6f9-a31f5c583225"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'gpt-4-1106-preview': ['gpt-4-1106-preview', 0.01, 0.03],\n",
              " 'gpt-3.5-turbo-1106': ['gpt-3.5-turbo-1106', 0.001, 0.002]}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_GPT = 'gpt-3.5-turbo-1106' # @param ['gpt-3.5-turbo-1106', 'gpt-4-1106-preview']\n",
        "top_documents = 8                # @param {type:'integer'} # Количество отобранных чанков\n",
        "temperature = 0                  # @param float            # Вариативность ответа\n",
        "limit_score = 0                  # @param float            # Отфильтровывать чанки при поиске выше этого значения, если '0' - не фильтровать\n",
        "question_norma = False           # @param {type:'boolean'} # Нормализовать вопрос - Удаляет лишние пробелы из вопроса\n",
        "url_prompt = 'https://raw.githubusercontent.com/terrainternship/GPT_Gavrilov_g/main/Ruslan_Grishakov/prompt' # @param {type:'string'}\n",
        "TelegramPosts_chat_prompt = load_file(url_prompt)"
      ],
      "metadata": {
        "id": "vNcLQ9VZmpcV"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g.chat_prompt = TelegramPosts_chat_prompt\n",
        "g.top_documents = top_documents\n",
        "g.temperature = temperature\n",
        "g.limit_score = limit_score\n",
        "g.question_norma = question_norma\n",
        "g.bd_index = TelegramPosts_bd_index\n",
        "g.gpt_model = MODEL_GPT\n",
        "g.SELECT_MODEL_GPT = MODEL_COST[g.gpt_model]\n",
        "g.select_sheet(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7VCq2RJW4y0",
        "outputId": "bef8b999-99b2-4311-866a-e9cf3a87f38b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Текущая страница - \"Аникеев\"\n",
            "\n",
            "-----№---------Название---\n",
            "Колонка №1  Вопрос\n",
            "Колонка №2  Ответ GPT\n",
            "Колонка №3  Оценка\n",
            "Колонка №4  Комментарий\n",
            "Колонка №5  Ошибка\n",
            "Колонка №6  Модель GPT\n",
            "Колонка №7  Промпт\n",
            "Колонка №8  Чанк №1\n",
            "Колонка №9  Чанк №2\n",
            "Колонка №10 Чанк №3\n",
            "Колонка №11 Чанк №4\n",
            "Колонка №12 Чанк №5\n",
            "Колонка №13 Чанк №6\n",
            "Колонка №14 Чанк №7\n",
            "Колонка №15 Чанк №8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g.chat_prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "ak0fRvVH-wtz",
        "outputId": "b6d2829c-6ac8-4d8e-ab3a-1251c048ba06"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Ты консультант по вопросам, связанным с систематизацией бизнеса, основываясь исключительно на информации, представленной в данном документе и текущем диалоге с клиентом. Не добавляй никакой информации из других источников и не используй внешние данные. Строго придерживайся только тех данных, которые содержатся в документе и текущем диалоге. Не упоминай клиенту о наличии документа с информацией и не давай понять, что твои ответы основаны на этом документе. Если информации в предоставленном документе и текущем диалоге недостаточно для ответа на вопрос клиента, сообщи об этом прямо, не пытаясь дополнять ответ внешними данными. Твоя задача - предоставлять точные и конкретные ответы, основанные исключительно на представленных данных. Если запрос клиента выходит за рамки тематики бизнес-систематизации или данных, содержащихся в диалоге и документе, объясни это клиенту, указав на отсутствие необходимой информации для ответа. Следуй инструкциям буквально и не предпринимай попыток интерпретировать или дополнять запросы клиента за рамками заданных критериев. Твоя главная цель - предоставить клиенту информацию, которая строго соответствует его запросам, опираясь на представленный контекст и документацию.\\nДля ответа используй не больше 2048 токенов и 4096 символов.\\nГаврилов Герман Александрович — бизнесмен, коуч и основатель сервисов аналитики и автоматизации бизнес-процессов Roistat и Platrum.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Загрузка вопросов\n",
        "g.load_sheet()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idT5EXR0-1W6",
        "outputId": "726a8dab-c7f5-4317-b050-9a17f816a18a",
        "cellView": "form"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Загрузка списка вопросов завершена. Количество вопросов: 8.\n",
            "Диапазон номеров строк с вопросами (включительно): [2:9].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Выбор диапазона вопросов группого запроса. Отправка запроса. { vertical-output: false }\n",
        "\n",
        "# Определение диапазона строк с вопросами. Начало диапазона, конец диапазона (включительно).\n",
        "row_first = 2      # @param {type:'integer'}\n",
        "row_end = 2        # @param {type:'integer'}\n",
        "verbose_answer = 0 # @param {type:'integer'}\n",
        "verbose_chank = 0  # @param {type:'integer'}\n",
        "g.execute(row_first, row_end, verbose_answer, verbose_chank)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbRiPvvg_BLb",
        "outputId": "2348ec3a-f90f-4a4b-a3d1-0a34b3e71a62",
        "cellView": "form"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Строка №2. Ответ на вопрос получен за - 4.595 сек.\n",
            "Строка №2. Ответ записан в файл.\n",
            "\n",
            "-------------------------------------------\n",
            "Вопросов в пакетной обработке - 1 шт.\n",
            "Время пакетной обработки      - 6.7 сек.\n",
            "Стоимость пакетной обработки  - 0.0058 $.\n",
            "Токенов в пакетной обработке  - 5633 шт.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Выбор диапазона вопросов группого запроса. Отправка запроса. { vertical-output: false }\n",
        "\n",
        "# Определение диапазона строк с вопросами. Начало диапазона, конец диапазона (включительно).\n",
        "row_first = 2      # @param {type:'integer'}\n",
        "row_end = 9        # @param {type:'integer'}\n",
        "verbose_answer = 0 # @param {type:'integer'}\n",
        "verbose_chank = 0  # @param {type:'integer'}\n",
        "g.execute(row_first, row_end, verbose_answer, verbose_chank)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36054dbc-7cd6-43b4-bc6f-a040424a1231",
        "cellView": "form",
        "id": "CwTbJxQmiC7H"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Строка №2. Ответ на вопрос получен за - 4.768 сек.\n",
            "Строка №2. Ответ записан в файл.\n",
            "Строка №3. Ответ на вопрос получен за - 2.76 сек.\n",
            "Строка №3. Ответ записан в файл.\n",
            "Строка №4. Ответ на вопрос получен за - 3.445 сек.\n",
            "Строка №4. Ответ записан в файл.\n",
            "Строка №5. Ответ на вопрос получен за - 7.289 сек.\n",
            "Строка №5. Ответ записан в файл.\n",
            "Строка №6. Ответ на вопрос получен за - 6.791 сек.\n",
            "Строка №6. Ответ записан в файл.\n",
            "Строка №7. Ответ на вопрос получен за - 13.01 сек.\n",
            "Строка №7. Ответ записан в файл.\n",
            "Строка №8. Ответ на вопрос получен за - 5.817 сек.\n",
            "Строка №8. Ответ записан в файл.\n",
            "Строка №9. Ответ на вопрос получен за - 2.801 сек.\n",
            "Строка №9. Ответ записан в файл.\n",
            "\n",
            "-------------------------------------------\n",
            "Вопросов в пакетной обработке - 8 шт.\n",
            "Время пакетной обработки      - 57.5 сек.\n",
            "Стоимость пакетной обработки  - 0.0428 $.\n",
            "Токенов в пакетной обработке  - 40970 шт.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Iki324RBw_iU",
        "C-vZQuEF4R93",
        "qnemPNyQZhfE",
        "12NdiiqSZxkL",
        "6hJrrs6v6De2",
        "Sn5N4dk08DU4"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}